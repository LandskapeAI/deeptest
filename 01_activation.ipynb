{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional\n",
    "\n",
    "> Test function output values against Wolfram | Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import wolframalpha\n",
    "from fastcore.test import *\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class WolframTester():\n",
    "    \n",
    "    def __init__(self, api_key, libdl):\n",
    "        self.key = api_key\n",
    "        self.libdl = libdl\n",
    "        self.cache = None\n",
    "        \n",
    "    \n",
    "    def query(self, expr):\n",
    "        client = wolframalpha.Client(self.key)\n",
    "        res = client.query(expr)\n",
    "        vals = list()\n",
    "        for pod in res.pods:\n",
    "            if pod['@title'] == 'Result':\n",
    "                val = float(pod['subpod']['plaintext'][:6])\n",
    "                vals.append(val)\n",
    "        return np.array(val)\n",
    "    \n",
    "    \n",
    "    def test(self, fn, fn_expr, xs, shape):\n",
    "        \n",
    "        if (self.cache is not None):\n",
    "            self.test_cache(fn, fn_expr, xs, shape)\n",
    "            return\n",
    "    \n",
    "        if (self.libdl == 'torch'):\n",
    "            ys = fn(xs).cpu().numpy()\n",
    "            test_eq(ys.shape, shape)\n",
    "            _xs = xs.cpu().detach().numpy().flatten()\n",
    "        \n",
    "        reals = list()\n",
    "\n",
    "        for x in _xs:\n",
    "            expr = re.sub('x', str(x), fn_expr)\n",
    "            res = self.query(expr)\n",
    "            reals.append(res)\n",
    "        \n",
    "        reals = np.array(reals).reshape(shape)\n",
    "        np.testing.assert_allclose(ys, reals, rtol=1e-2, atol=1e-5)\n",
    "        \n",
    "        self.cache = {fn_expr : (xs, reals)}\n",
    "        self.save_cache(fn.__name__)\n",
    "        \n",
    "    \n",
    "    def test_cache(self, fn, fn_expr, xs, shape):\n",
    "        self.load_cache(fn.__name__)\n",
    "        xs, reals = self.cache[fn_expr]\n",
    "        \n",
    "        if (self.libdl == 'torch'):\n",
    "            ys = fn(xs).cpu().numpy()\n",
    "            test_eq(ys.shape, shape)\n",
    "            xs = xs.cpu().detach().numpy().flatten()\n",
    "        \n",
    "        np.testing.assert_allclose(ys, reals, rtol=1e-2, atol=1e-5)\n",
    "        \n",
    "        \n",
    "    def save_cache(self, name):\n",
    "        with open(f'{name}.pkl', 'wb') as f:\n",
    "            pickle.dump(self.cache, f, pickle.HIGHEST_PROTOCOL)\n",
    "            print(\"Stored Cache\")\n",
    "\n",
    "    def load_cache(self, name):\n",
    "        with open(f'{name}.pkl', 'rb') as f:\n",
    "            self.cache = pickle.load(f)\n",
    "            print(\"Loaded Cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function = torch.tanh\n",
    "xs = torch.tensor([[[[-10, -8, -6, -4, -2], [0, 2, 4, 6, 8]]]], dtype=torch.float32)\n",
    "shape = (1, 1, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = WolframTester('YOUR_API_KEY', 'torch')\n",
    "tester = WolframTester('QYU645-4EGHX3JVLE', 'torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time the test function is executed, it queries the Wolfram API. This function call will be slow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored Cache\n",
      "CPU times: user 226 ms, sys: 33.9 ms, total: 260 ms\n",
      "Wall time: 41.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tester.test(function, 'tanh(x)', xs, shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now, the inputs and expected outputs are cached on disk in `.pkl` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh.pkl\r\n"
     ]
    }
   ],
   "source": [
    "! ls *.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So subsequent function calls are much faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Cache\n",
      "CPU times: user 2.63 ms, sys: 2.77 ms, total: 5.4 ms\n",
      "Wall time: 9.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tester.test(function, 'tanh(x)', xs, shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
